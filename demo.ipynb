{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cba8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import json\n",
    "import pathlib\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48906c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lbartolome/TOVA/.venv/lib/python3.12/site-packages/spacy/cli/_util.py:23: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n",
      "/Users/lbartolome/TOVA/.venv/lib/python3.12/site-packages/weasel/util/config.py:8: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-12 17:15:43 [__init__.py:216] Automatically detected platform cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tomotopyLDA': tova.topic_models.models.traditional.tomotopy_lda_tm_model.TomotopyLDATMmodel,\n",
       " 'CTM': tova.topic_models.models.traditional.ctmtm_model.CTMTMmodel,\n",
       " 'topicGPT': tova.topic_models.models.llm_based.topicgpt.topicgpt_tm_model.TopicGPTTMmodel,\n",
       " 'OpenTopicRAGModel': tova.topic_models.models.llm_based.open_topic_rag_model.OpenTopicRAGModel}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./static/config/modelRegistry.json\", \"r\") as f:\n",
    "    model_classes = json.load(f)\n",
    "    \n",
    "def load_class_from_path(class_path: str):\n",
    "    module_path, class_name = class_path.rsplit(\".\", 1)\n",
    "    module = importlib.import_module(module_path)\n",
    "    return getattr(module, class_name)\n",
    "\n",
    "\n",
    "MODEL_REGISTRY = {\n",
    "    key: load_class_from_path(path) for key, path in model_classes.items()\n",
    "}\n",
    "\n",
    "MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c166b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"topicGPT\"\n",
    "model_name = \"test_nb\"\n",
    "id = \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1bb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"data_test/bills_sample_100.csv\"\n",
    "train_data = pd.read_csv(data_file).sample(1000, random_state=42)\n",
    "train_data = train_data.rename(columns={\"summary\": \"raw_text\"})\n",
    "train_data = train_data[[\"id\", \"raw_text\"]].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd8ac9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model_cls = MODEL_REGISTRY.get(\u001b[43mmodel\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_cls = MODEL_REGISTRY.get(model)\n",
    "if model_cls is None:\n",
    "    raise ValueError(f\"Unknown model: {model}\")\n",
    "\n",
    "tr_params = {\n",
    "    #\"num_topics\": 50,\n",
    "    #\"preprocess_text\": False,\n",
    "  }\n",
    "\n",
    "tm_model = model_cls(\n",
    "    model_name=model_name,\n",
    "    corpus_id=\"c_4e3634ace8f94d8e899142ef637348c0\",\n",
    "    id=id,\n",
    "    model_path=pathlib.Path(f\"data/tests/test_{model_name}\"),\n",
    "    load_model=False,\n",
    "    logger=logging.getLogger(f\"test_logger_{model_name}\"),\n",
    "    **tr_params\n",
    ")\n",
    "\n",
    "mo = tm_model.train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c2986a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5195919e-04, 1.1186427e-03, 7.5819204e-04, ..., 1.3817464e-04,\n",
       "        3.4841048e-04, 1.0000000e-12],\n",
       "       [1.0000000e-12, 2.7100969e-04, 3.8097534e-04, ..., 1.0000000e-12,\n",
       "        1.0000000e-12, 5.4258919e-05],\n",
       "       [1.0000000e-12, 4.2435946e-04, 6.1949290e-04, ..., 2.0160321e-04,\n",
       "        1.8074561e-04, 5.8819231e-05],\n",
       "       ...,\n",
       "       [1.0000000e-12, 1.0000000e-12, 4.6570780e-04, ..., 1.0000000e-12,\n",
       "        3.5667632e-04, 1.0000000e-12],\n",
       "       [1.0000000e-12, 2.1579172e-04, 1.9501198e-04, ..., 5.3309137e-04,\n",
       "        2.9871159e-04, 1.0000000e-12],\n",
       "       [1.0000000e-12, 1.0000000e-12, 1.0000000e-12, ..., 1.0000000e-12,\n",
       "        1.0000000e-12, 1.0000000e-12]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas = tm_model.tm_model._thetas\n",
    "alphas= tm_model.tm_model._alphas\n",
    "betas = tm_model.tm_model._betas\n",
    "vocab = tm_model.tm_model._vocab\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0841b475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99999994, 1.        , 1.        , 0.9999999 ,\n",
       "       0.99999994, 1.        , 1.        , 1.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if betas sum to 1\n",
    "np.sum(betas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b35fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndocs = 10000\n",
    "validDocs = np.sum(thetas.toarray(), axis=1) > 0\n",
    "nValidDocs = np.sum(validDocs)\n",
    "if ndocs > nValidDocs:\n",
    "    ndocs = nValidDocs\n",
    "perm = np.sort(np.random.permutation(nValidDocs)[:ndocs])\n",
    "doc_len = ndocs * [1]\n",
    "vocabfreq = np.round(ndocs*(alphas.dot(betas))).astype(int)\n",
    "\n",
    "vis_data = pyLDAvis.prepare(\n",
    "    betas,\n",
    "    thetas[validDocs, ][perm, ].toarray(),\n",
    "    doc_len,\n",
    "    vocab,\n",
    "    vocabfreq,\n",
    "    lambda_step=0.05,\n",
    "    sort_topics=False,\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954d1a5",
   "metadata": {},
   "source": [
    "# OPENRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3c1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"OpenTopicRAGModel\"\n",
    "model_name = \"test_nb\"\n",
    "id = \"xxx\"\n",
    "data_file = \"data_test/bills_sample_100.csv\"\n",
    "train_data = pd.read_csv(data_file).sample(1000, random_state=42)\n",
    "train_data = train_data.rename(columns={\"summary\": \"raw_text\"})\n",
    "train_data = train_data[[\"id\", \"raw_text\"]].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd891a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config file static/config/config.yaml and section logger.\n",
      "Logs will be saved in data/logs\n",
      "Loaded config file static/config/config.yaml and section llm.\n",
      "tova.prompter.prompter - INFO - Using OLLAMA API with host: http://kumo01.tsc.uc3m.es:11434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "OpenTopicRAG Iterations:   0%|                              | 0/2 [00:00<?, ?it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: 0456dcb0b14e723c2eb547d4c1ea4816\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Topic discovery complete: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.16it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Retrieval complete:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/4 [00:00<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: 85dddff7bf48ff83b96685a9dfcd205f\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: a6e771fddbcdae951e002e151cefb9f5\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: 9a298fbd0362bec6fa4739235c344025\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: 1ee2ff0f17503768de6fe3bf75b4ee53\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: 90e42e1b0783b99ad468bd16f0a6aca2\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysis complete:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 1/5 [00:03<00:14,  3.63s/it]\n",
      "Cleanup complete: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 475.01it/s]\n",
      "OpenTopicRAG Iterations:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 1/2 [00:07<00:07,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Results for this iteration:\n",
      "Primary Topic Discovered: **  â€œTax Relief and Revenue Modificationsâ€\n",
      "User Preferences Applied: None\n",
      "\n",
      "Document Analysis:\n",
      "\n",
      "1. Document excerpt: Amends the Emergency Economic Stabilization Act of 2008 (EESA) to require that a...\n",
      "   Discovered Topic: Troubled Asset Relief Program (TARP) Repayment & Debt Reduction\n",
      "   Related Themes: Fiscal Policy, Government Intervention, Financial Stability\n",
      "   Relevance Score: 9.0/10\n",
      "   Sentiment: neutral\n",
      "   Key Entities: Troubled Asset Relief Program (TARP), Emergency Economic Stabilization Act of 2008, Public Debt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: 30ca8ce3c606707ec38ec865fe4404bc\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Topic discovery complete: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.15s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Retrieval complete:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/4 [00:00<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: f745276012ebff3b0ee7560e6a869b8f\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: d3c948fb35cefb4ae436c7b5589aaa20\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: a488518a7423471a05535662ea5c22ae\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: ccae6645d4d0b594f5f65a3828ba725b\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: 7097a41c0fdae47f196dd6fcbda13dc4\n",
      "Cache miss: computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysis complete:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 1/5 [00:04<00:16,  4.02s/it]\n",
      "Cleanup complete: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 245.53it/s]\n",
      "OpenTopicRAG Iterations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.34s/it]\n",
      "INFO:TMmodel:-- -- -- Topic model object (TMmodel) successfully created\n",
      "INFO:TMmodel:-- -- Sorted\n",
      "INFO:TMmodel:-- -- betas ds\n",
      "INFO:TMmodel:-- -- entropy\n",
      "INFO:TMmodel:-- -- active\n",
      "INFO:TMmodel:-- -- descriptions\n",
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n",
      "INFO:gensim.corpora.dictionary:built Dictionary<17979 unique tokens: ['\"State', '(1)', '(2)', '(3)', '(4)']...> from 1000 documents (total 184408 corpus positions)\n",
      "INFO:gensim.utils:Dictionary lifecycle event {'msg': 'built Dictionary<17979 unique tokens: [\\'\"State\\', \\'(1)\\', \\'(2)\\', \\'(3)\\', \\'(4)\\']...> from 1000 documents (total 184408 corpus positions)', 'datetime': '2026-01-12T17:16:50.988187', 'gensim': '4.3.3', 'python': '3.12.8 (main, Jan 16 2025, 15:52:49) [Clang 16.0.0 (clang-1600.0.26.4)]', 'platform': 'macOS-26.2-arm64-arm-64bit', 'event': 'created'}\n",
      "INFO:TMmodel:Calculating just coherence c_npmi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Results for this iteration:\n",
      "Primary Topic Discovered: ** **U.S. Manufacturing Competitiveness & Government Support for Advanced Manufacturing**\n",
      "User Preferences Applied: None\n",
      "\n",
      "Document Analysis:\n",
      "\n",
      "1. Document excerpt: Antitrust Modernization Commission Extension Act of 2007 - Amends the Antitrust ...\n",
      "   Discovered Topic: Antitrust Legislation & Commission Extension\n",
      "   Related Themes: Antitrust, Government Regulation, Commission Reporting\n",
      "   Relevance Score: 4.0/10\n",
      "   Sentiment: neutral\n",
      "   Key Entities: Antitrust Modernization Commission, President, Congress\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unable to interpret topic as either a list of tokens or a list of ids",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      5\u001b[39m tr_params = {\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m#\"num_topics\": 50,\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m#\"preprocess_text\": False,\u001b[39;00m\n\u001b[32m      8\u001b[39m   }\n\u001b[32m     10\u001b[39m tm_model = model_cls(\n\u001b[32m     11\u001b[39m     model_name=model_name,\n\u001b[32m     12\u001b[39m     corpus_id=\u001b[33m\"\u001b[39m\u001b[33mc_4e3634ace8f94d8e899142ef637348c0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     **tr_params\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m mo = \u001b[43mtm_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TOVA/src/tova/topic_models/models/llm_based/base.py:103\u001b[39m, in \u001b[36mLLMTModel.train_model\u001b[39m\u001b[34m(self, data, progress_callback, cancel)\u001b[39m\n\u001b[32m    101\u001b[39m prs = pr.report_subrange(\u001b[32m0.7\u001b[39m, \u001b[32m0.9\u001b[39m)\n\u001b[32m    102\u001b[39m prs.report(\u001b[32m0.0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCreating TMmodel object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_createTMmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m prs.report(\u001b[32m1.0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTMmodel object created\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# 4. SAVE MODEL\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# (90-100%)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TOVA/src/tova/topic_models/models/base_model.py:160\u001b[39m, in \u001b[36mBaseTMModel._createTMmodel\u001b[39m\u001b[34m(self, thetas, betas, vocab)\u001b[39m\n\u001b[32m    148\u001b[39m alphas = np.asarray(np.mean(thetas, axis=\u001b[32m0\u001b[39m)).ravel()\n\u001b[32m    150\u001b[39m tm = TMmodel(\n\u001b[32m    151\u001b[39m     TMfolder=\u001b[38;5;28mself\u001b[39m.model_path.joinpath(\u001b[33m'\u001b[39m\u001b[33mTMmodel\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    152\u001b[39m     config_path=\u001b[38;5;28mself\u001b[39m._config_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m     summarizer_prompt=\u001b[38;5;28mself\u001b[39m.summarizer_prompt,\n\u001b[32m    159\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[43mtm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43malphas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28mself\u001b[39m.tm_model = tm\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TOVA/src/tova/topic_models/tm_model.py:176\u001b[39m, in \u001b[36mTMmodel.create\u001b[39m\u001b[34m(self, betas, thetas, alphas, vocab)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28mself\u001b[39m._tpc_descriptions = [el[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_tpc_word_descriptions()]\n\u001b[32m    175\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33m-- -- descriptions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalculate_topic_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28mself\u001b[39m._load_vocab_dicts()\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m#self._calculate_s3()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TOVA/src/tova/topic_models/tm_model.py:566\u001b[39m, in \u001b[36mTMmodel.calculate_topic_coherence\u001b[39m\u001b[34m(self, metrics, n_words, reference_text, only_one, aggregated)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\n\u001b[32m    564\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalculating just coherence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mc_npmi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mu_mass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mc_v\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mc_uci\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     cm = \u001b[43mCoherenceModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtpc_descriptions_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m     \u001b[38;5;28mself\u001b[39m._topic_coherence = cm.get_coherence_per_topic()\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m aggregated:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TOVA/.venv/lib/python3.12/site-packages/gensim/models/coherencemodel.py:214\u001b[39m, in \u001b[36mCoherenceModel.__init__\u001b[39m\u001b[34m(self, model, topics, texts, corpus, dictionary, window_size, keyed_vectors, coherence, topn, processes)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28mself\u001b[39m._accumulator = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m._topics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtopics\u001b[49m = topics\n\u001b[32m    216\u001b[39m \u001b[38;5;28mself\u001b[39m.processes = processes \u001b[38;5;28;01mif\u001b[39;00m processes >= \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, mp.cpu_count() - \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TOVA/.venv/lib/python3.12/site-packages/gensim/models/coherencemodel.py:429\u001b[39m, in \u001b[36mCoherenceModel.topics\u001b[39m\u001b[34m(self, topics)\u001b[39m\n\u001b[32m    427\u001b[39m new_topics = []\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m topics:\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     topic_token_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_elements_are_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     new_topics.append(topic_token_ids)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TOVA/.venv/lib/python3.12/site-packages/gensim/models/coherencemodel.py:453\u001b[39m, in \u001b[36mCoherenceModel._ensure_elements_are_ids\u001b[39m\u001b[34m(self, topic)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array(ids_from_ids)\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33munable to interpret topic as either a list of tokens or a list of ids\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: unable to interpret topic as either a list of tokens or a list of ids"
     ]
    }
   ],
   "source": [
    "model_cls = MODEL_REGISTRY.get(model)\n",
    "if model_cls is None:\n",
    "    raise ValueError(f\"Unknown model: {model}\")\n",
    "\n",
    "tr_params = {\n",
    "    #\"num_topics\": 50,\n",
    "    #\"preprocess_text\": False,\n",
    "  }\n",
    "\n",
    "tm_model = model_cls(\n",
    "    model_name=model_name,\n",
    "    corpus_id=\"c_4e3634ace8f94d8e899142ef637348c0\",\n",
    "    id=id,\n",
    "    model_path=pathlib.Path(f\"data/tests/test_{model_name}\"),\n",
    "    load_model=False,\n",
    "    logger=logging.getLogger(f\"test_logger_{model_name}\"),\n",
    "    **tr_params\n",
    ")\n",
    "\n",
    "mo = tm_model.train_model(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
