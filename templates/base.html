<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>{% block title %}TOVA - Topic Visualization{% endblock %}</title>

  {% if csrf_token is defined %}
    <meta name="csrf-token" content="{{ csrf_token() }}">
  {% endif %}

  <link
    href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
    rel="stylesheet"
  >
  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css"
  >

  <style>
    body {
      font-family: Arial, sans-serif;
      display: flex;
      flex-direction: column;
      min-height: 100vh;
    }
    .hero {
      flex: 1;
      display: flex;
      align-items: center;
      justify-content: center;
      text-align: left;
      padding: 30px;
    }
    .hero img {
      max-width: 40%;
      height: auto;
      border-radius: 10px;
    }
    .hero-content {
      max-width: 50%;
      padding-left: 30px;
    }
    footer {
      margin-top: auto;
    }
    @media (max-width: 576px) {
      .hero h1 {
        font-size: 1.75rem;
      }
      .hero p {
        font-size: 1rem;
      }
    }

    .navbar-nav .nav-link.active {
      font-weight: 600;
    }
    .navbar-nav .nav-link:hover {
      text-decoration: underline;
    }
  </style>

  {% block extra_head %}{% endblock %}
</head>
<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light shadow-sm">
    <div class="container">
      <a class="navbar-brand fw-bold" href="{{ url_for('home') }}">TOVA</a>

      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarContent"
              aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon" aria-hidden="true"></span>
      </button>

      <div class="collapse navbar-collapse justify-content-between" id="navbarContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link {% if request.endpoint == 'home' %}active{% endif %}"
               href="{{ url_for('home') }}">
              Upload Data
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link {% if request.endpoint == 'loadModel' %}active{% endif %}"
               href="{{ url_for('loadModel') }}">
              Initiate Training
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link {% if request.endpoint == 'trained_models' %}active{% endif %}"
               href="{{ url_for('trained_models') }}">
              Model Repository
            </a>
          </li>
        </ul>

        <div class="d-flex align-items-center gap-2">
          {% if user %}
            <span class="navbar-text small text-muted d-none d-md-inline">
              Hi, {{ user.name }}
            </span>
            <button class="btn btn-success btn-sm" data-bs-toggle="modal" data-bs-target="#configModal">
              Config Editor
            </button>
            <a href="{{ url_for('logout') }}" class="btn btn-outline-secondary btn-sm">
              Logout
            </a>
          {% else %}
            <a href="{{ url_for('login') }}" class="btn btn-outline-primary btn-sm">
              Login
            </a>
            <a href="{{ url_for('signup') }}" class="btn btn-success btn-sm">
              Sign up
            </a>
          {% endif %}
        </div>
      </div>
    </div>
  </nav>

  <div class="container mt-3">
    {% with messages = get_flashed_messages(with_categories=true) %}
      {% if messages %}
        {% for category, message in messages %}
          <div class="alert alert-{{ category }} py-2 mb-2" role="alert">
            {{ message }}
          </div>
        {% endfor %}
      {% endif %}
    {% endwith %}
  </div>

  <main class="flex-grow-1">
    {% block content %}{% endblock %}
  </main>

  {% if user %}
<div class="modal fade" id="configModal" tabindex="-1" aria-labelledby="configModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-xl modal-dialog-scrollable">
    <form class="modal-content" id="configForm">
      <div class="modal-header bg-light">
        <h5 class="modal-title fw-bold" id="configModalLabel"><i class="bi bi-gear-fill me-2"></i>Global Configuration Editor</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>

      <div class="modal-body p-4">
        <div class="alert alert-info small d-flex align-items-center gap-2" role="status">
          <i class="bi bi-person-gear"></i>
          <span>Your configuration is saved to your account and defaults to <code>static/config/config.yaml</code>.</span>
        </div>
        <div id="configStatus" class="text-secondary small mb-2 d-none">
          <i class="bi bi-info-circle me-1"></i>
          <span id="configStatusText">Loading your configuration...</span>
        </div>
        <div class="d-flex justify-content-between align-items-center mb-3">
          <div class="small text-muted">Last update: <span id="configLastSaved">not loaded</span></div>
          <div class="btn-group btn-group-sm">
            <button type="button" class="btn btn-outline-secondary" id="configRefreshBtn">Reload</button>
            <button type="button" class="btn btn-outline-danger" id="configResetBtn">Reset to defaults</button>
          </div>
        </div>
        <div id="llm-feedback" class="alert small" style="display:none;" aria-live="polite"></div>

        <ul class="nav nav-pills nav-fill mb-4 border-bottom pb-2" id="configTabs" role="tablist">
          <li class="nav-item" role="presentation"><button class="nav-link active" id="logger-tab" data-bs-toggle="tab" data-bs-target="#logger-pane" type="button" role="tab" aria-controls="logger-pane" aria-selected="true"><i class="bi bi-journal-text me-1"></i> Logging</button></li>
          <li class="nav-item" role="presentation"><button class="nav-link" id="topic-modeling-tab" data-bs-toggle="tab" data-bs-target="#topic-modeling-pane" type="button" role="tab" aria-controls="topic-modeling-pane" aria-selected="false"><i class="bi bi-tags-fill me-1"></i> Topic Modeling</button></li>
          <li class="nav-item" role="presentation"><button class="nav-link" id="preprocessor-tab" data-bs-toggle="tab" data-bs-target="#preprocessor-pane" type="button" role="tab" aria-controls="preprocessor-pane" aria-selected="false"><i class="bi bi-funnel-fill me-1"></i> Preprocessing</button></li>
          <li class="nav-item" role="presentation"><button class="nav-link" id="llm-tab" data-bs-toggle="tab" data-bs-target="#llm-pane" type="button" role="tab" aria-controls="llm-pane" aria-selected="false"><i class="bi bi-robot me-1"></i> LLM/Prompter</button></li>
        </ul>

        <div class="tab-content" id="configTabsContent">

          <div class="tab-pane fade show active" id="logger-pane" role="tabpanel" aria-labelledby="logger-tab" tabindex="0">
            <h4 class="mb-3">Log Settings</h4>
            <div class="row">
              <div class="col-md-6 mb-3">
                <label for="logger-dir_logger" class="form-label">Log Directory</label>
                <input type="text" class="form-control" id="logger-dir_logger" name="logger.dir_logger" placeholder="data/logs">
                <div class="form-text">Relative path to store log files.</div>
              </div>
              <div class="col-md-6 mb-3">
                <label for="logger-log_level" class="form-label">Log Level</label>
                <select class="form-select" id="logger-log_level" name="logger.log_level">
                  <option value="DEBUG">DEBUG</option>
                  <option value="INFO">INFO</option>
                  <option value="WARNING">WARNING</option>
                  <option value="ERROR">ERROR</option>
                </select>
                <div class="form-text">Minimum severity level to record.</div>
              </div>
            </div>
            <div class="row">
              <div class="col-md-4 mb-3 form-check form-switch p-4 bg-light rounded">
                <input class="form-check-input" type="checkbox" role="switch" id="logger-console_log" name="logger.console_log">
                <label class="form-check-label ms-2" for="logger-console_log">Enable Console Logging</label>
              </div>
              <div class="col-md-4 mb-3 form-check form-switch p-4 bg-light rounded">
                <input class="form-check-input" type="checkbox" role="switch" id="logger-file_log" name="logger.file_log">
                <label class="form-check-label ms-2" for="logger-file_log">Enable File Logging</label>
              </div>
              <div class="col-md-4 mb-3">
                <label for="logger-N_log_keep" class="form-label">Max Log Files to Keep (N_log_keep)</label>
                <input type="number" class="form-control" id="logger-N_log_keep" name="logger.N_log_keep" min="1" value="5">
              </div>
            </div>
          </div>

          <div class="tab-pane fade" id="topic-modeling-pane" role="tabpanel" aria-labelledby="topic-modeling-tab" tabindex="0">
            <h4 class="mb-3">Topic Modeling Algorithms & Global Params</h4>
            
            <ul class="nav nav-tabs nav-justified mb-3" id="topicModelSubTabs" role="tablist">
              <li class="nav-item" role="presentation"><button class="nav-link active" id="tm-general-tab" data-bs-toggle="pill" data-bs-target="#tm-general" type="button" role="tab">General Settings</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="tm-traditional-tab" data-bs-toggle="pill" data-bs-target="#tm-traditional" type="button" role="tab">Traditional/DFT</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="tm-llm-based-tab" data-bs-toggle="pill" data-bs-target="#tm-llm-based" type="button" role="tab">LLM-based</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="tm-bertopic-tab" data-bs-toggle="pill" data-bs-target="#tm-bertopic" type="button" role="tab">BERTopic</button></li>
            </ul>
            
            <div class="tab-content card card-body bg-light" id="topicModelSubTabsContent">
              
              <div class="tab-pane fade show active" id="tm-general" role="tabpanel" aria-labelledby="tm-general-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Model Output Filters</h6>
                <div class="row">
                  <div class="col-md-4 mb-3">
                    <label for="tm-general-n_similar_tpcs" class="form-label">n_similar_tpcs</label>
                    <input type="number" class="form-control" id="tm-general-n_similar_tpcs" name="topic_modeling.general.n_similar_tpcs" value="5">
                    <div class="form-text small">Number of similar topics to find.</div>
                  </div>
                  <div class="col-md-4 mb-3">
                    <label for="tm-general-similar_tpcs_thr" class="form-label">similar_tpcs_thr (Threshold)</label>
                    <input type="text" class="form-control" id="tm-general-similar_tpcs_thr" name="topic_modeling.general.similar_tpcs_thr" value="1e-3">
                    <div class="form-text small">Similarity threshold for topic comparison.</div>
                  </div>
                  <div class="col-md-4 mb-3">
                    <label for="tm-general-n_top_docs_per_topic" class="form-label">n_top_docs_per_topic</label>
                    <input type="number" class="form-control" id="tm-general-n_top_docs_per_topic" name="topic_modeling.general.n_top_docs_per_topic" value="20">
                    <div class="form-text small">Top documents to show per topic.</div>
                  </div>
                </div>
                <hr class="my-3">
                <h6 class="mb-3">Default LLM Provider Settings <span class="badge bg-secondary ms-2">Optional</span></h6>
                <div class="alert alert-info d-flex align-items-start gap-2 mb-3" role="alert">
                  <i class="bi bi-info-circle mt-1"></i>
                  <div class="small">
                    These are default LLM settings used when no provider is specified. Configure the provider details in the <strong>LLM/Prompter</strong> tab above.
                  </div>
                </div>
                <div class="row">
                  <div class="col-md-4 mb-3">
                    <label for="tm-general-llm_provider" class="form-label">LLM Provider</label>
                    <select class="form-select" id="tm-general-llm_provider" name="topic_modeling.general.llm_provider">
                      <option value="ollama">Ollama</option>
                      <option value="gpt">GPT (OpenAI)</option>
                      <option value="llama_cpp">Llama.cpp</option>
                    </select>
                    <div class="form-text small">Default provider for LLM operations.</div>
                  </div>
                  <div class="col-md-4 mb-3">
                    <label for="tm-general-llm_model_type" class="form-label">LLM Model</label>
                    <input type="text" class="form-control" id="tm-general-llm_model_type" name="topic_modeling.general.llm_model_type" value="gemma3:4b" placeholder="e.g., qwen:32b, gpt-4o">
                    <div class="form-text small">Model name (must match available models for selected provider).</div>
                  </div>
                  <div class="col-md-4 mb-3">
                    <label for="tm-general-llm_server" class="form-label">LLM Server URL</label>
                    <input type="url" class="form-control" id="tm-general-llm_server" name="topic_modeling.general.llm_server" value="http://kumo01.tsc.uc3m.es:11434" placeholder="http://localhost:11434">
                    <div class="form-text small">Server URL (only needed for Ollama/Llama.cpp).</div>
                  </div>
                </div>
                <hr class="my-3">
                <div class="mb-3">
                  <label for="tm-general-not_include" class="form-label">not_include (Variables to exclude from saving)</label>
                  <textarea class="form-control form-control-sm" id="tm-general-not_include" name="topic_modeling.general.not_include" rows="3" placeholder="Comma-separated list (e.g., train_data, df, embeddings, ...)">train_data, df, embeddings, ids_corpus, _logger, _embedding_model, _umap_model, _hdbscan_model, _vectorizer_model, _ctfidf_model, _representation_model, _model</textarea>
                  <div class="form-text">These Python objects will be skipped during model saving.</div>
                </div>
              </div>

              <div class="tab-pane fade" id="tm-traditional" role="tabpanel" aria-labelledby="tm-traditional-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Traditional Topic Modeling (LDA, NMF, etc.)</h6>
                <div class="row">
                  <div class="col-md-4 mb-3">
                    <label for="tm-trad-num_topics" class="form-label">num_topics</label>
                    <input type="number" class="form-control" id="tm-trad-num_topics" name="topic_modeling.traditional.num_topics" value="15" min="2">
                    <div class="form-text small">Number of topics to extract.</div>
                  </div>
                  <div class="col-md-4 mb-3">
                    <label for="tm-trad-thetas_thr" class="form-label">thetas_thr</label>
                    <input type="text" class="form-control" id="tm-trad-thetas_thr" name="topic_modeling.traditional.thetas_thr" value="3e-3">
                    <div class="form-text small">Threshold for document-topic probabilities.</div>
                  </div>
                  <div class="col-md-4 mb-3">
                    <label for="tm-trad-topn" class="form-label">Top N Words</label>
                    <input type="number" class="form-control" id="tm-trad-topn" name="topic_modeling.traditional.topn" value="15" min="1">
                    <div class="form-text small">Number of top words per topic.</div>
                  </div>
                </div>
                <hr class="my-3">
                <h6 class="mb-3">LLM Post-Processing <span class="badge bg-secondary ms-2">Optional</span></h6>
                <div class="alert alert-info d-flex align-items-start gap-2 mb-3" role="alert">
                  <i class="bi bi-info-circle mt-1"></i>
                  <div class="small">
                    <strong>Optional Enhancement:</strong> You can use LLMs to automatically label and summarize topics after training. This requires LLM configuration in the <strong>LLM/Prompter</strong> tab. If disabled, topics will use word-based labels.
                  </div>
                </div>
                <div class="row">
                  <div class="col-md-6 mb-3 form-check form-switch p-3 bg-white rounded border">
                    <input class="form-check-input" type="checkbox" role="switch" id="tm-trad-do_labeller" name="topic_modeling.traditional.do_labeller" checked>
                    <label class="form-check-label ms-2" for="tm-trad-do_labeller">
                      <strong>Enable LLM Labeller</strong>
                      <div class="form-text small">Generate descriptive labels for topics using LLM.</div>
                    </label>
                  </div>
                  <div class="col-md-6 mb-3 form-check form-switch p-3 bg-white rounded border">
                    <input class="form-check-input" type="checkbox" role="switch" id="tm-trad-do_summarizer" name="topic_modeling.traditional.do_summarizer" checked>
                    <label class="form-check-label ms-2" for="tm-trad-do_summarizer">
                      <strong>Enable LLM Summarizer</strong>
                      <div class="form-text small">Generate summaries for each topic using LLM.</div>
                    </label>
                  </div>
                </div>
                <div class="row" id="tm-trad-llm-settings">
                  <div class="col-md-6 mb-3">
                    <label for="tm-trad-llm_model_type" class="form-label">LLM Model</label>
                    <input type="text" class="form-control" id="tm-trad-llm_model_type" name="topic_modeling.traditional.llm_model_type" value="qwen:32b" placeholder="e.g., qwen:32b, gpt-4o">
                    <div class="form-text small">Model name (must be available in your LLM provider).</div>
                  </div>
                  <div class="col-md-6 mb-3">
                    <label for="tm-trad-llm_server" class="form-label">LLM Server URL</label>
                    <input type="url" class="form-control" id="tm-trad-llm_server" name="topic_modeling.traditional.llm_server" value="http://kumo01.tsc.uc3m.es:11434" placeholder="http://localhost:11434">
                    <div class="form-text small">Server URL (only needed for Ollama/Llama.cpp providers).</div>
                  </div>
                </div>
                <div class="row" id="tm-trad-prompt-settings">
                  <div class="col-md-6 mb-3">
                    <label for="tm-trad-labeller_prompt" class="form-label">Labeller Prompt Path</label>
                    <input type="text" class="form-control" id="tm-trad-labeller_prompt" name="topic_modeling.traditional.labeller_prompt" value="src/tova/prompter/prompts/labelling_dft.txt">
                    <div class="form-text small">Path to prompt template for topic labeling.</div>
                  </div>
                  <div class="col-md-6 mb-3">
                    <label for="tm-trad-summarizer_prompt" class="form-label">Summarizer Prompt Path</label>
                    <input type="text" class="form-control" id="tm-trad-summarizer_prompt" name="topic_modeling.traditional.summarizer_prompt" value="src/tova/prompter/prompts/summarization_dft.txt">
                    <div class="form-text small">Path to prompt template for topic summarization.</div>
                  </div>
                </div>
              </div>

              <div class="tab-pane fade" id="tm-llm-based" role="tabpanel" aria-labelledby="tm-llm-based-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Settings for LLM-Based Topic Modeling</h6>
                <div class="alert alert-warning d-flex align-items-start gap-2 mb-3" role="alert">
                  <i class="bi bi-exclamation-triangle mt-1"></i>
                  <div class="small">
                    <strong>LLM Required:</strong> LLM-based topic modeling requires a fully configured LLM provider. Make sure you've set up your LLM provider in the <strong>LLM/Prompter</strong> tab before using these models.
                  </div>
                </div>
                <div class="mb-3">
                  <label for="tm-llm-based-llm" class="form-label">Default LLM Model <span class="text-danger">*</span></label>
                  <input type="text" class="form-control" id="tm-llm-based-llm" name="topic_modeling.llm-based.llm" value="qwen:32b" placeholder="e.g., qwen:32b, gpt-4o">
                  <div class="form-text">Model name that matches your configured LLM provider.</div>
                </div>
                <div class="mb-3">
                  <label for="tm-llm-based-llm_server" class="form-label">LLM Server URL</label>
                  <input type="url" class="form-control" id="tm-llm-based-llm_server" name="topic_modeling.llm-based.llm_server" value="http://kumo01.tsc.uc3m.es:11434" placeholder="http://localhost:11434">
                  <div class="form-text">Server URL (only needed for Ollama/Llama.cpp providers). Not needed for OpenAI GPT.</div>
                </div>
              </div>
              
              <div class="tab-pane fade" id="tm-bertopic" role="tabpanel" aria-labelledby="tm-bertopic-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">BERTopic Configuration</h6>
                <div class="row">
                  <div class="col-md-4 mb-3"><label for="tm-bertopic-language" class="form-label">Language</label><input type="text" class="form-control" id="tm-bertopic-language" name="topic_modeling.bertopic.language" value="english"></div>
                  <div class="col-md-8 mb-3"><label for="tm-bertopic-sbert_model" class="form-label">Sentence-BERT Model</label><input type="text" class="form-control" id="tm-bertopic-sbert_model" name="topic_modeling.bertopic.sbert_model" value="all-MiniLM-L6-v2"></div>
                </div>
                <hr>
                <fieldset class="border p-3 mb-3 bg-white rounded">
                    <legend class="float-none w-auto px-2 fs-6 fw-bold">UMAP Reduction Settings</legend>
                    <div class="row">
                      <div class="col-md-3 mb-3"><label for="tm-bertopic-umap_n_components" class="form-label">n_components</label><input type="number" class="form-control" id="tm-bertopic-umap_n_components" name="topic_modeling.bertopic.umap_n_components" value="5"></div>
                      <div class="col-md-3 mb-3"><label for="tm-bertopic-umap_n_neighbors" class="form-label">n_neighbors</label><input type="number" class="form-control" id="tm-bertopic-umap_n_neighbors" name="topic_modeling.bertopic.umap_n_neighbors" value="15"></div>
                      <div class="col-md-3 mb-3"><label for="tm-bertopic-umap_min_dist" class="form-label">min_dist</label><input type="text" class="form-control" id="tm-bertopic-umap_min_dist" name="topic_modeling.bertopic.umap_min_dist" value="0.0"></div>
                      <div class="col-md-3 mb-3"><label for="tm-bertopic-umap_metric" class="form-label">metric</label><input type="text" class="form-control" id="tm-bertopic-umap_metric" name="topic_modeling.bertopic.umap_metric" value="cosine"></div>
                    </div>
                </fieldset>
                
                <fieldset class="border p-3 mb-3 bg-white rounded">
                    <legend class="float-none w-auto px-2 fs-6 fw-bold">HDBSCAN Clustering Settings</legend>
                    <div class="row">
                      <div class="col-md-4 mb-3"><label for="tm-bertopic-hdbscan_min_cluster_size" class="form-label">min_cluster_size</label><input type="number" class="form-control" id="tm-bertopic-hdbscan_min_cluster_size" name="topic_modeling.bertopic.hdbscan_min_cluster_size" value="10"></div>
                      <div class="col-md-4 mb-3"><label for="tm-bertopic-hdbscan_metric" class="form-label">metric</label><input type="text" class="form-control" id="tm-bertopic-hdbscan_metric" name="topic_modeling.bertopic.hdbscan_metric" value="euclidean"></div>
                      <div class="col-md-4 mb-3"><label for="tm-bertopic-hdbscan_cluster_selection_method" class="form-label">selection_method</label><input type="text" class="form-control" id="tm-bertopic-hdbscan_cluster_selection_method" name="topic_modeling.bertopic.hdbscan_cluster_selection_method" value="eom"></div>
                      <div class="col-md-4 mb-3 form-check form-switch"><input class="form-check-input" type="checkbox" role="switch" id="tm-bertopic-hbdsan_prediction_data" name="topic_modeling.bertopic.hbdsan_prediction_data" checked><label class="form-check-label ms-2" for="tm-bertopic-hbdsan_prediction_data">Enable Prediction Data</label></div>
                    </div>
                </fieldset>
                
                <hr>
                <div class="row">
                  <div class="col-md-6 mb-3"><label for="tm-bertopic-repr_model_diversity" class="form-label">Representation Diversity</label><input type="number" step="0.1" class="form-control" id="tm-bertopic-repr_model_diversity" name="topic_modeling.bertopic.repr_model_diversity" value="0.3"></div>
                  <div class="col-md-6 mb-3"><label for="tm-bertopic-repr_model_topnwords" class="form-label">Top N Words (Representation)</label><input type="number" class="form-control" id="tm-bertopic-repr_model_topnwords" name="topic_modeling.bertopic.repr_model_topnwords" value="15"></div>
                </div>
              </div>

            </div>
          </div>

          <div class="tab-pane fade" id="preprocessor-pane" role="tabpanel" aria-labelledby="preprocessor-tab" tabindex="0">
            <h4 class="mb-3">Text Cleaning and Transformation</h4>
             
            <ul class="nav nav-tabs nav-justified mb-3" id="preprocessorSubTabs" role="tablist">
              <li class="nav-item" role="presentation"><button class="nav-link active" id="pp-spacy-tab" data-bs-toggle="pill" data-bs-target="#pp-spacy" type="button" role="tab"><i class="bi bi-robot me-1"></i> SpaCy</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="pp-vectorization-tab" data-bs-toggle="pill" data-bs-target="#pp-vectorization" type="button" role="tab"><i class="bi bi-grid me-1"></i> Vectorization</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="pp-embeddings-tab" data-bs-toggle="pill" data-bs-target="#pp-embeddings" type="button" role="tab"><i class="bi bi-infinity me-1"></i> Embeddings</button></li>
            </ul>
            
            <div class="tab-content card card-body bg-light">
              <div class="tab-pane fade show active" id="pp-spacy" role="tabpanel" aria-labelledby="pp-spacy-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">SpaCy Settings</h6>
                <div class="mb-3"><label for="pp-spacy-model" class="form-label">SpaCy Model Name</label><input type="text" class="form-control" id="pp-spacy-model" name="tm_preprocessor.spacy.spacy_model" value="en_core_web_sm"></div>
                <div class="mb-3">
                    <label for="pp-spacy-disable" class="form-label">Disable Components (Comma Separated)</label>
                    <input type="text" class="form-control" id="pp-spacy-disable" name="tm_preprocessor.spacy.spacy_disable" value="ner, parser">
                    <div class="form-text">e.g., `ner, parser`</div>
                </div>
                <div class="mb-3">
                    <label for="pp-spacy-valid_pos" class="form-label">Valid Parts-of-Speech (Comma Separated)</label>
                    <input type="text" class="form-control" id="pp-spacy-valid_pos" name="tm_preprocessor.spacy.valid_pos" value="VERB, NOUN, ADJ, PROPN">
                    <div class="form-text">e.g., `VERB, NOUN, ADJ, PROPN`</div>
                </div>
              </div>
              
              <div class="tab-pane fade" id="pp-vectorization" role="tabpanel" aria-labelledby="pp-vectorization-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Count/TF-IDF Vectorization</h6>
                <div class="row">
                  <div class="col-md-4 mb-3"><label for="pp-vector-max_features" class="form-label">max_features</label><input type="number" class="form-control" id="pp-vector-max_features" name="tm_preprocessor.vectorization.max_features" value="100000"></div>
                  <div class="col-md-4 mb-3"><label for="pp-vector-min_df" class="form-label">min_df</label><input type="text" class="form-control" id="pp-vector-min_df" name="tm_preprocessor.vectorization.min_df" value="1"></div>
                  <div class="col-md-4 mb-3"><label for="pp-vector-max_df" class="form-label">max_df</label><input type="text" class="form-control" id="pp-vector-max_df" name="tm_preprocessor.vectorization.max_df" value="1"></div>
                </div>
                <div class="row">
                  <div class="col-md-6 mb-3">
                    <label for="pp-vector-ngram_range" class="form-label">ngram_range</label>
                    <input type="text" class="form-control" id="pp-vector-ngram_range" name="tm_preprocessor.vectorization.ngram_range" value="[1, 2]">
                    <div class="form-text">e.g., `[1, 2]`</div>
                  </div>
                  <div class="col-md-6 mb-3 form-check form-switch p-4 bg-white rounded">
                    <input class="form-check-input" type="checkbox" role="switch" id="pp-vector-binary" name="tm_preprocessor.vectorization.binary">
                    <label class="form-check-label ms-2" for="pp-vector-binary">Binary (count presence only)</label>
                  </div>
                </div>
              </div>
              
              <div class="tab-pane fade" id="pp-embeddings" role="tabpanel" aria-labelledby="pp-embeddings-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Sentence Embedding Settings</h6>
                <div class="mb-3"><label for="pp-embed-model_name" class="form-label">Embedding Model Name</label><input type="text" class="form-control" id="pp-embed-model_name" name="tm_preprocessor.embeddings.model_name" value="all-MiniLM-L6-v2"></div>
                <div class="row">
                  <div class="col-md-6 mb-3 form-check form-switch p-4 bg-white rounded">
                    <input class="form-check-input" type="checkbox" role="switch" id="pp-embed-normalize" name="tm_preprocessor.embeddings.normalize" checked>
                    <label class="form-check-label ms-2" for="pp-embed-normalize">Normalize Embeddings</label>
                  </div>
                  <div class="col-md-6 mb-3"><label for="pp-embed-batch_size" class="form-label">Batch Size</label><input type="number" class="form-control" id="pp-embed-batch_size" name="tm_preprocessor.embeddings.batch_size" value="32"></div>
                </div>
              </div>
            </div>

          </div>

          <div class="tab-pane fade" id="llm-pane" role="tabpanel" aria-labelledby="llm-tab" tabindex="0">
            <div class="alert alert-info d-flex align-items-start gap-2 mb-4" role="alert">
              <i class="bi bi-info-circle mt-1"></i>
              <div class="flex-grow-1">
                <strong>LLM Configuration is Optional</strong>
                <p class="mb-0 small">You only need to configure LLM settings if you plan to use LLM-based features like topic labeling, summarization, or LLM-based topic modeling. If you're using traditional topic models without LLM post-processing, you can skip this section.</p>
              </div>
            </div>

            <h4 class="mb-3">LLM Generation Parameters & Providers</h4>
            
            <ul class="nav nav-tabs nav-justified mb-3" id="llmSubTabs" role="tablist">
              <li class="nav-item" role="presentation"><button class="nav-link active" id="llm-params-tab" data-bs-toggle="pill" data-bs-target="#llm-params" type="button" role="tab">Global Parameters</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="llm-gpt-tab" data-bs-toggle="pill" data-bs-target="#llm-gpt" type="button" role="tab">GPT (OpenAI)</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="llm-ollama-tab" data-bs-toggle="pill" data-bs-target="#llm-ollama" type="button" role="tab">Ollama (Local)</button></li>
              <li class="nav-item" role="presentation"><button class="nav-link" id="llm-llama-cpp-tab" data-bs-toggle="pill" data-bs-target="#llm-llama-cpp" type="button" role="tab">Llama.cpp</button></li>
            </ul>

            <div class="tab-content card card-body bg-light">
              <div class="tab-pane fade show active" id="llm-params" role="tabpanel" aria-labelledby="llm-params-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Model Generation Controls</h6>
                <p class="text-muted small mb-3">These parameters control how the LLM generates text. Default values work well for most use cases.</p>
                <div class="row">
                  <div class="col-md-3 mb-3">
                    <label for="llm-params-temperature" class="form-label">Temperature <span class="text-muted small">(0-2)</span></label>
                    <input type="number" step="0.01" min="0" max="2" class="form-control" id="llm-params-temperature" name="llm.parameters.temperature" value="0">
                    <div class="form-text small">Controls randomness. Lower = more deterministic.</div>
                  </div>
                  <div class="col-md-3 mb-3">
                    <label for="llm-params-top_p" class="form-label">Top P <span class="text-muted small">(0-1)</span></label>
                    <input type="number" step="0.01" min="0" max="1" class="form-control" id="llm-params-top_p" name="llm.parameters.top_p" value="0.1">
                    <div class="form-text small">Nucleus sampling threshold.</div>
                  </div>
                  <div class="col-md-3 mb-3">
                    <label for="llm-params-frequency_penalty" class="form-label">Frequency Penalty</label>
                    <input type="number" step="0.01" class="form-control" id="llm-params-frequency_penalty" name="llm.parameters.frequency_penalty" value="0.0">
                    <div class="form-text small">Reduces repetition. Range: -2.0 to 2.0</div>
                  </div>
                  <div class="col-md-3 mb-3">
                    <label for="llm-params-random_seed" class="form-label">Random Seed</label>
                    <input type="number" class="form-control" id="llm-params-random_seed" name="llm.parameters.random_seed" value="1234">
                    <div class="form-text small">For reproducible outputs.</div>
                  </div>
                </div>
              </div>

              <div class="tab-pane fade" id="llm-gpt" role="tabpanel" aria-labelledby="llm-gpt-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">OpenAI (GPT) Settings <span class="badge bg-secondary ms-2">Optional</span></h6>
                <div class="alert alert-warning d-flex align-items-start gap-2 mb-3" role="alert">
                  <i class="bi bi-exclamation-triangle mt-1"></i>
                  <div class="small">
                    <strong>API Key Required:</strong> You need an OpenAI API key to use GPT models. Store it in a <code>.env</code> file or the path specified below.
                  </div>
                </div>
                <div class="mb-3">
                  <label for="llm-gpt-path_api_key" class="form-label">API Key Path <span class="text-danger">*</span></label>
                  <input type="text" class="form-control" id="llm-gpt-path_api_key" name="llm.gpt.path_api_key" value=".env" placeholder=".env">
                  <div class="form-text">Path to file containing your OpenAI API key (e.g., <code>.env</code>). The file should contain: <code>OPENAI_API_KEY=your-key-here</code></div>
                </div>
                <div class="mb-3">
                  <label class="form-label">Available Models (Read-Only)</label>
                  <textarea class="form-control form-control-sm" rows="4" readonly style="resize:none; overflow-y: scroll; font-family: monospace; font-size: 0.85em;">gpt-4o-2024-08-06, gpt-4o-mini-2024-07-18, chatgpt-4o-latest, gpt-4-turbo, gpt-4-turbo-2024-04-09, gpt-4, gpt-3.5-turbo, gpt-4o-mini, gpt-4o, gpt-4-32k, gpt-4-0125-preview, gpt-4-1106-preview, gpt-4-vision-preview, gpt-3.5-turbo-0125, gpt-3.5-turbo-instruct, gpt-3.5-turbo-1106, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, gpt-3.5-turbo-0301</textarea>
                  <div class="form-text small">These models are available when using OpenAI. Select one when configuring topic models.</div>
                </div>
              </div>

              <div class="tab-pane fade" id="llm-ollama" role="tabpanel" aria-labelledby="llm-ollama-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Ollama Settings <span class="badge bg-secondary ms-2">Optional</span></h6>
                <div class="alert alert-info d-flex align-items-start gap-2 mb-3" role="alert">
                  <i class="bi bi-info-circle mt-1"></i>
                  <div class="small">
                    <strong>Local/Remote Ollama Server:</strong> Ollama allows you to run LLMs locally or on a remote server. Make sure your Ollama server is running and accessible at the URL below.
                  </div>
                </div>
                <div class="mb-3">
                  <label for="llm-ollama-host" class="form-label">Host URL <span class="text-danger">*</span></label>
                  <input type="url" class="form-control" id="llm-ollama-host" name="llm.ollama.host" value="http://kumo01.tsc.uc3m.es:11434" placeholder="http://localhost:11434">
                  <div class="form-text">URL of your Ollama server. Default: <code>http://localhost:11434</code> for local installations.</div>
                </div>
                <div class="mb-3">
                  <label class="form-label">Available Models (Read-Only)</label>
                  <textarea class="form-control form-control-sm" rows="3" readonly style="resize:none; overflow-y: scroll; font-family: monospace; font-size: 0.85em;">llama3.2, llama3.1:8b-instruct-q8_0, qwen:32b, llama3.3:70b, qwen2.5:32b</textarea>
                  <div class="form-text small">These models are available when using Ollama. Make sure they are installed on your Ollama server: <code>ollama pull &lt;model-name&gt;</code></div>
                </div>
              </div>

              <div class="tab-pane fade" id="llm-llama-cpp" role="tabpanel" aria-labelledby="llm-llama-cpp-tab" tabindex="0">
                <h6 class="border-bottom pb-2 mb-3">Llama.cpp Settings <span class="badge bg-secondary ms-2">Optional</span></h6>
                <div class="alert alert-info d-flex align-items-start gap-2 mb-3" role="alert">
                  <i class="bi bi-info-circle mt-1"></i>
                  <div class="small">
                    <strong>Llama.cpp Server:</strong> Configure this if you're using a llama.cpp compatible server. This is typically for advanced users running custom LLM servers.
                  </div>
                </div>
                <div class="mb-3">
                  <label for="llm-llama-cpp-host" class="form-label">Host URL <span class="text-danger">*</span></label>
                  <input type="url" class="form-control" id="llm-llama-cpp-host" name="llm.llama_cpp.host" value="http://kumo01:11435/v1/chat/completions" placeholder="http://localhost:11435/v1/chat/completions">
                  <div class="form-text">URL endpoint for your llama.cpp server. Must support OpenAI-compatible API format.</div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="modal-footer">
        <button type="submit" class="btn btn-success" id="configSaveBtn"><i class="bi bi-save me-2"></i>Save Configuration</button>
        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
      </div>
    </form>
  </div>
</div>
{% endif %}

  <footer class="bg-dark text-white text-center py-2">
    <p class="mb-0">&copy; 2025 TOVA. Internal Research Tool.</p>
  </footer>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js" defer></script>
  

{% if user %}
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const configForm = document.getElementById('configForm');
      if (!configForm) return;

      const configModalEl = document.getElementById('configModal');
      const feedbackDiv = document.getElementById('llm-feedback');
      const statusRow = document.getElementById('configStatus');
      const statusText = document.getElementById('configStatusText');
      const lastSavedSpan = document.getElementById('configLastSaved');
      const refreshBtn = document.getElementById('configRefreshBtn');
      const resetBtn = document.getElementById('configResetBtn');
      const saveBtn = document.getElementById('configSaveBtn');

      const showFeedback = (message, variant = 'success') => {
        if (!feedbackDiv) return;
        feedbackDiv.textContent = message;
        feedbackDiv.className = `alert alert-${variant} small`;
        feedbackDiv.style.display = 'block';
      };

      const clearFeedback = () => {
        if (feedbackDiv) feedbackDiv.style.display = 'none';
      };

      const setLoading = (isLoading, text = 'Loading...') => {
        if (statusRow) statusRow.classList.toggle('d-none', !isLoading);
        if (statusText && text) statusText.textContent = text;
        [saveBtn, resetBtn, refreshBtn].forEach((btn) => {
          if (btn) btn.disabled = isLoading;
        });
      };

      const updateLastSaved = (value) => {
        if (!lastSavedSpan) return;
        if (!value) {
          lastSavedSpan.textContent = 'using defaults';
          return;
        }
        const date = value instanceof Date ? value : new Date(value);
        lastSavedSpan.textContent = date.toLocaleString();
      };

      // Build ID-to-path mapping cache from DOM (optimized - no hardcoding)
      // This is built once and reused, using the existing 'name' attributes
      let idToPathCache = null;
      const buildIdToPathCache = () => {
        if (idToPathCache !== null) return idToPathCache; // Return cached version
        idToPathCache = new Map();
        const inputs = configForm.querySelectorAll("input[id], textarea[id], select[id]");
        inputs.forEach((el) => {
          if (el.id && el.name) {
            idToPathCache.set(el.id, el.name);
          }
        });
        return idToPathCache;
      };

      // Get config path for an element ID (optimized with cache)
      const getIdToPath = (id) => {
        const cache = buildIdToPathCache();
        return cache.get(id) || id; // Fallback to ID if not found
      };

      // Reusable param collector (optimized version - same approach as training modal)
      const collectParamsFromContainer = (container) => {
        const out = {};
        if (!container) return out;
        
        // Build cache once if not already built
        buildIdToPathCache();
        
        const inputs = container.querySelectorAll("input, textarea, select");
        inputs.forEach((el) => {
          const id = el.id;
          if (!id) return;

          // Skip provider-specific fields that are hidden
          const llmSection = el.closest(".llm-provider-section");
          if (llmSection && (llmSection.classList.contains("d-none") || !(document.querySelector("#include_llm")?.checked))) return;

          // Skip hidden LLM settings in traditional topic modeling if LLM features are disabled
          const llmSettingsRow = document.getElementById('tm-trad-llm-settings');
          const promptSettingsRow = document.getElementById('tm-trad-prompt-settings');
          if ((llmSettingsRow && llmSettingsRow.contains(el) && llmSettingsRow.style.display === 'none') ||
              (promptSettingsRow && promptSettingsRow.contains(el) && promptSettingsRow.style.display === 'none')) {
            return;
          }

          // Get config path from cache (uses name attribute)
          const path = getIdToPath(id);
          if (!path || path === id) return; // Skip if no valid path found

          // Handle special case for not_include (array)
          if (path.includes("not_include")) {
            const items = String(el.value || "")
              .split(/[\n,]/)
              .map((s) => s.trim())
              .filter(Boolean);
            setNestedValue(path, items, out);
            return;
          }

          // Handle checkboxes
          if (el.type === "checkbox") {
            setNestedValue(path, el.checked, out);
            return;
          }

          const raw = el.value;
          const trimmed = raw != null ? raw.trim() : "";
          
          // Handle numbers (allow empty/zero values)
          if (el.type === "number") {
            const n = Number(trimmed);
            if (Number.isFinite(n)) {
              setNestedValue(path, n, out);
            }
            return;
          }

          // Skip empty text fields (but allow empty strings for textareas if needed)
          // Exception: Don't skip LLM fields that are marked as optional - let them be empty
          if (!trimmed && el.tagName !== "TEXTAREA") {
            // Only skip if it's not an LLM-related field (these can be empty)
            const isLLMField = path.includes('llm.') || path.includes('llm_provider') || path.includes('llm_model') || path.includes('llm_server');
            if (!isLLMField) return;
          }

          // Handle text/textarea/select
          setNestedValue(path, trimmed, out);
        });
        return out;
      };

      function setNestedValue(key, value, obj) {
        const parts = key.split('.');
        let current = obj;
        for (let i = 0; i < parts.length; i++) {
          const part = parts[i];
          if (i === parts.length - 1) {
            current[part] = value;
          } else {
            if (!current[part] || typeof current[part] !== 'object') {
              current[part] = {};
            }
            current = current[part];
          }
        }
      }

      const formatForInput = (value) => {
        if (Array.isArray(value)) return value.join(', ');
        return value;
      };

      // Optimized form population using cache (reverse lookup)
      function populateForm(config, prefix = '') {
        // Build reverse cache (path -> element) for faster lookups
        if (!populateForm._pathToElementCache) {
          populateForm._pathToElementCache = new Map();
          const cache = buildIdToPathCache();
          cache.forEach((path, id) => {
            const element = configForm.querySelector(`#${id}`);
            if (element) {
              populateForm._pathToElementCache.set(path, element);
            }
          });
          // Also cache direct name lookups
          configForm.querySelectorAll('[name]').forEach((el) => {
            if (el.name && !populateForm._pathToElementCache.has(el.name)) {
              populateForm._pathToElementCache.set(el.name, el);
            }
          });
        }

        for (const key in config) {
          if (!Object.hasOwn(config, key)) continue;
          const fullKey = prefix ? `${prefix}.${key}` : key;
          const value = config[key];

          if (value && typeof value === 'object' && !Array.isArray(value)) {
            populateForm(value, fullKey);
          } else {
            // Use cached lookup (much faster than querySelector)
            const element = populateForm._pathToElementCache.get(fullKey);

            if (element) {
              if (element.type === 'checkbox') {
                element.checked = Boolean(value);
              } else if (['number', 'text', 'url'].includes(element.type) || ['TEXTAREA', 'SELECT'].includes(element.tagName)) {
                const formatted = formatForInput(value);
                element.value = formatted === undefined || formatted === null ? '' : formatted;
              }
            }
          }
        }
      }
      
      // Clear cache when form is reset/reloaded
      const clearFormCaches = () => {
        idToPathCache = null;
        populateForm._pathToElementCache = null;
      };

      const collectConfig = () => {
        return collectParamsFromContainer(configForm);
      };

      async function fetchAndFill() {
        clearFeedback();
        setLoading(true, 'Loading your configuration...');
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 10000);
        try {
          const res = await fetch('/api/user-config', {
            headers: { 'Accept': 'application/json' },
            signal: controller.signal,
          });
          if (!res.ok) throw new Error(`Load failed (${res.status})`);
          const data = await res.json();
          populateForm(data || {});
          updateLastSaved(new Date());
          showFeedback('Loaded your saved configuration.', 'info');
        } catch (err) {
          console.error(err);
          showFeedback(err.message || 'Failed to load your config.', 'danger');
        } finally {
          clearTimeout(timeoutId);
          setLoading(false);
          setTimeout(clearFeedback, 4000);
        }
      }

      configForm.addEventListener('submit', async function(e) {
        e.preventDefault();
        clearFeedback();

        const newConfig = collectConfig();
        setLoading(true, 'Saving...');

        try {
          const response = await fetch("/api/user-config", {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify(newConfig)
          });

          const result = await response.json().catch(() => ({}));

          if (response.ok && result.success !== false) {
            updateLastSaved(new Date());
            showFeedback(result.message || 'Configuration saved successfully!', 'success');
          } else {
            throw new Error(result.message || `Error (${response.status}): Failed to save settings.`);
          }
        } catch (error) {
          console.error(error);
          showFeedback(error.message || 'An error occurred while communicating with the server.', 'danger');
        } finally {
          setLoading(false);
          setTimeout(() => {
            if (feedbackDiv) feedbackDiv.style.display = 'none';
          }, 5000);
        }
      });

      refreshBtn?.addEventListener('click', (event) => {
        event.preventDefault();
        clearFormCaches(); // Clear caches on refresh
        fetchAndFill();
      });

      resetBtn?.addEventListener('click', async (event) => {
        event.preventDefault();
        clearFeedback();

        const confirmed = window.confirm('Reset to defaults from config.yaml?');
        if (!confirmed) return;

        setLoading(true, 'Resetting to defaults...');
        try {
          const response = await fetch("/api/user-config/reset", { method: 'POST' });
          const result = await response.json().catch(() => ({}));
          if (response.ok && result.success !== false) {
            clearFormCaches(); // Clear caches on reset
            populateForm(result.config || {});
            updateLastSaved(null);
            showFeedback('Configuration reset to defaults.', 'info');
          } else {
            throw new Error(result.message || `Reset failed (${response.status}).`);
          }
        } catch (error) {
          console.error(error);
          showFeedback(error.message || 'Failed to reset configuration.', 'danger');
        } finally {
          setLoading(false);
          setTimeout(() => {
            if (feedbackDiv) feedbackDiv.style.display = 'none';
          }, 5000);
        }
      });

      fetchAndFill();

      // Ensure spinner is hidden if modal is closed while a request is in flight
      configModalEl?.addEventListener('hidden.bs.modal', () => setLoading(false));

      // Handle conditional LLM settings visibility in traditional topic modeling
      const labellerCheckbox = document.getElementById('tm-trad-do_labeller');
      const summarizerCheckbox = document.getElementById('tm-trad-do_summarizer');
      const llmSettingsRow = document.getElementById('tm-trad-llm-settings');
      const promptSettingsRow = document.getElementById('tm-trad-prompt-settings');

      const updateLLMSettingsVisibility = () => {
        const showLLM = labellerCheckbox?.checked || summarizerCheckbox?.checked;
        if (llmSettingsRow) {
          llmSettingsRow.style.display = showLLM ? 'flex' : 'none';
          // Make fields optional when hidden
          llmSettingsRow.querySelectorAll('input').forEach(input => {
            if (!showLLM) {
              input.removeAttribute('required');
              input.setAttribute('data-was-optional', 'true');
            }
          });
        }
        if (promptSettingsRow) {
          promptSettingsRow.style.display = showLLM ? 'flex' : 'none';
          promptSettingsRow.querySelectorAll('input').forEach(input => {
            if (!showLLM) {
              input.removeAttribute('required');
              input.setAttribute('data-was-optional', 'true');
            }
          });
        }
      };

      labellerCheckbox?.addEventListener('change', updateLLMSettingsVisibility);
      summarizerCheckbox?.addEventListener('change', updateLLMSettingsVisibility);
      
      // Initialize visibility on load
      updateLLMSettingsVisibility();
    });
  </script>
{% endif %}

  {% block extra_scripts %}{% endblock %}
</body>
</html>